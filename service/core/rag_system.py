"""
RAG ì‹œìŠ¤í…œ í†µí•© ì»´í¬ë„ŒíŠ¸
ê²€ìƒ‰ ì¦ê°• ìƒì„±(Retrieval-Augmented Generation) ê¸°ëŠ¥ì„ ì œê³µ
GPT-4.1 ê¸°ë°˜ í’ˆì§ˆ í‰ê°€ ë° MongoDB ë¡œê¹… í¬í•¨
"""

import logging
import asyncio
from typing import List, Dict, Any
from dataclasses import dataclass

from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from service.storage.vector_store import search_similar_documents
from admin.tools.document_indexer import get_document_indexer
from service.storage.rag_logger import evaluate_and_log_rag, quick_rag_score, RAGEvaluationResult
from pydantic import BaseModel

logger = logging.getLogger(__name__)

@dataclass
class RAGConfig:
    """RAG ì‹œìŠ¤í…œ ì„¤ì •"""
    embedding_model: str = "BAAI/bge-m3"
    max_retrieved_docs: int = 5
    similarity_threshold: float = 0.3
    max_context_length: int = 4000

class RAGResponse(BaseModel):
    """RAG ì‘ë‹µ ëª¨ë¸"""
    answer: str
    retrieved_documents: List[Dict[str, Any]]
    context_used: str
    confidence_score: float
    quality_score: float = 0.0  # GPT-4.1 í’ˆì§ˆ í‰ê°€ ì ìˆ˜ (0-10)
    evaluation_result: Dict[str, Any] = None  # ìƒì„¸ í‰ê°€ ê²°ê³¼

class RAGSystem:
    """RAG ì‹œìŠ¤í…œ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, config: RAGConfig = None):
        self.config = config or RAGConfig()
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.embed_model = HuggingFaceEmbedding(
            model_name=self.config.embedding_model
        )
        
        logger.info("RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def query(self, question: str, max_docs: int = None) -> RAGResponse:
        """
        RAG ì¿¼ë¦¬ ì‹¤í–‰
        
        Args:
            question (str): ì‚¬ìš©ì ì§ˆë¬¸
            max_docs (int): ìµœëŒ€ ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜
            
        Returns:
            RAGResponse: RAG ì‘ë‹µ
        """
        try:
            max_docs = max_docs or self.config.max_retrieved_docs
            
            # 1. ì§ˆë¬¸ ì„ë² ë”© ìƒì„±
            question_embedding = self.embed_model.get_text_embedding(question)
            
            # 2. ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ (ë” ë§ì´ ê²€ìƒ‰í•´ì„œ ì¤‘ë³µ ì œê±° í›„ í•„í„°ë§)
            similar_docs = await search_similar_documents(
                query_embedding=question_embedding,
                limit=max_docs * 3  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ ë” ë§ì´ ê²€ìƒ‰
            )
            
            # 3. ê°™ì€ source_file ì¤‘ë³µ ì œê±° ë° í†µí•©
            deduplicated_docs = self._deduplicate_by_source_file(similar_docs)
            
            # 4. ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§ (ìœ ì‚¬ë„ ì„ê³„ê°’)
            filtered_docs = [
                doc for doc in deduplicated_docs 
                if doc.get('score', 0) >= self.config.similarity_threshold
            ]
            
            # 5. ìš”ì²­ëœ ë¬¸ì„œ ìˆ˜ë¡œ ì œí•œ
            filtered_docs = filtered_docs[:max_docs]
            
            # 6. ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = self._build_context(filtered_docs)
            
            # 7. ë‹µë³€ ìƒì„± (í˜„ì¬ëŠ” ê¸°ë³¸ ì‘ë‹µ, í–¥í›„ LLM ì—°ë™)
            answer = self._generate_answer(question, context, filtered_docs)
            
            # 8. ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
            confidence = self._calculate_confidence(filtered_docs)
            
            # 9. RAG í’ˆì§ˆ í‰ê°€ ë° MongoDB ë¡œê¹… (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰)
            quality_score = 0.0
            evaluation_result = None
            
            try:
                # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ í’ˆì§ˆ í‰ê°€ ë° ë¡œê¹… ì‹¤í–‰
                if context and answer:
                    asyncio.create_task(
                        self._evaluate_and_log_quality(question, context, answer)
                    )
                    
                    # ë¹ ë¥¸ í’ˆì§ˆ ì ìˆ˜ë§Œ ê°€ì ¸ì˜¤ê¸° (ë¸”ë¡œí‚¹í•˜ì§€ ì•ŠìŒ)
                    quality_score = await quick_rag_score(question, context, answer)
                    
            except Exception as e:
                logger.warning(f"RAG í’ˆì§ˆ í‰ê°€ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
            
            return RAGResponse(
                answer=answer,
                retrieved_documents=filtered_docs,
                context_used=context,
                confidence_score=confidence,
                quality_score=quality_score
            )
            
        except Exception as e:
            logger.error(f"RAG ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return RAGResponse(
                answer="ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                retrieved_documents=[],
                context_used="",
                confidence_score=0.0
            )
    
    def _deduplicate_by_source_file(self, documents: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ê°™ì€ source_fileì˜ ë¬¸ì„œë“¤ì„ ì¤‘ë³µ ì œê±°í•˜ê³  í†µí•©"""
        if not documents:
            return []
        
        # source_fileë³„ë¡œ ê·¸ë£¹í™”
        file_groups = {}
        for doc in documents:
            source_file = doc.get('source_file', 'unknown')
            if source_file not in file_groups:
                file_groups[source_file] = []
            file_groups[source_file].append(doc)
        
        # ê° íŒŒì¼ë³„ë¡œ ìµœê³  ì ìˆ˜ ì²­í¬ë¥¼ ëŒ€í‘œë¡œ ì„ íƒí•˜ê³  í…ìŠ¤íŠ¸ í†µí•©
        deduplicated = []
        for source_file, docs in file_groups.items():
            # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
            docs.sort(key=lambda x: x.get('score', 0), reverse=True)
            
            # ìµœê³  ì ìˆ˜ ë¬¸ì„œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í…ìŠ¤íŠ¸ í†µí•©
            representative_doc = docs[0].copy()
            
            # ìƒìœ„ 5ê°œ ì²­í¬ì˜ í…ìŠ¤íŠ¸ë¥¼ ê²°í•© (ë” ë§ì€ ì •ë³´ í¬í•¨)
            combined_texts = []
            for doc in docs[:5]:
                text = doc.get('text', '').strip()
                if text and text not in combined_texts:
                    combined_texts.append(text)
            
            # í…ìŠ¤íŠ¸ ê²°í•©
            combined_text = '\n\n'.join(combined_texts)
            representative_doc['text'] = combined_text
            representative_doc['combined_chunks'] = len(docs)
            
            deduplicated.append(representative_doc)
        
        # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ë°˜í™˜
        deduplicated.sort(key=lambda x: x.get('score', 0), reverse=True)
        return deduplicated
    
    def _build_context(self, documents: List[Dict[str, Any]]) -> str:
        """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ë¡œë¶€í„° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        if not documents:
            return ""
        
        context_parts = []
        current_length = 0
        
        for i, doc in enumerate(documents):
            doc_text = doc.get('text', '')
            source_file = doc.get('source_file', 'unknown')
            
            # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ í™•ì¸
            if current_length + len(doc_text) > self.config.max_context_length:
                break
            
            context_part = f"[ë¬¸ì„œ {i+1} - {source_file}]\n{doc_text}\n"
            context_parts.append(context_part)
            current_length += len(context_part)
        
        return "\n".join(context_parts)
    
    def _generate_answer(self, question: str, context: str, documents: List[Dict[str, Any]]) -> str:
        """
        ë‹µë³€ ìƒì„± (ê°„ê²°í•œ ë²„ì „)
        
        Args:
            question (str): ì‚¬ìš©ì ì§ˆë¬¸
            context (str): ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸
            documents (List[Dict[str, Any]]): ê²€ìƒ‰ëœ ë¬¸ì„œë“¤
            
        Returns:
            str: ìƒì„±ëœ ë‹µë³€
        """
        if not documents:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œê°€ ì¸ë±ì‹±ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
        
        # ì»¨í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œ
        context_lines = context.split('\n')
        answer_lines = []
        
        for line in context_lines:
            line = line.strip()
            # ë¬¸ì„œ í—¤ë” ë¼ì¸ì€ ì œì™¸
            if line.startswith('[ë¬¸ì„œ') or not line:
                continue
            # í•µì‹¬ ë‚´ìš©ë§Œ í¬í•¨
            answer_lines.append(line)
        
        # ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë²„ì „)
        question_lower = question.lower()
        question_keywords = []
        
        # ì§ˆë¬¸ ìœ í˜•ë³„ í‚¤ì›Œë“œ ë§¤í•‘
        keyword_patterns = {
            'ìœ„ì¹˜': ['ìœ„ì¹˜', 'ì£¼ì†Œ', 'ë¶€ì„œ', 'ì¸µ', 'ê±´ë¬¼', 'ê³³'],
            'ì‹œê°„': ['ì‹œê°„', 'ì–¸ì œ', 'ëª‡ì‹œ', 'ì‹œê°', 'ì¼ì •'],
            'ë°©ë²•': ['ë°©ë²•', 'ì–´ë–»ê²Œ', 'ì ˆì°¨', 'ê³¼ì •', 'ë‹¨ê³„'],
            'ì—°ë½ì²˜': ['ì—°ë½ì²˜', 'ì „í™”', 'ë²ˆí˜¸', 'ë©”ì¼', 'ì´ë©”ì¼'],
            'ì°¨ëŸ‰': ['ì°¨ëŸ‰', 'ìë™ì°¨', 'ì…€í† ìŠ¤', 'xm3', 'ì£¼ì°¨', 'ì˜ˆì•½'],
            'ë¹„ìš©': ['ë¹„ìš©', 'ìš”ê¸ˆ', 'ê°€ê²©', 'ëˆ', 'ë¹„', 'ê¸ˆì•¡'],
            'ì‚¬ìš©': ['ì‚¬ìš©', 'ì´ìš©', 'í™œìš©', 'ì ‘ê·¼', 'ë¡œê·¸ì¸']
        }
        
        # ì§ˆë¬¸ì—ì„œ ê´€ë ¨ í‚¤ì›Œë“œ ì°¾ê¸°
        for category, keywords in keyword_patterns.items():
            if any(keyword in question_lower for keyword in keywords):
                question_keywords.extend(keywords)
        
        # ë‹µë³€ ì¡°í•©
        if answer_lines:
            # í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê´€ë ¨ì„± ìˆëŠ” ë‚´ìš©ë§Œ í•„í„°ë§
            if question_keywords:
                filtered_content = []
                for line in answer_lines:
                    line_lower = line.lower()
                    if any(keyword in line_lower for keyword in question_keywords):
                        filtered_content.append(line)
                
                if filtered_content:
                    return '\n'.join(filtered_content)
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ì´ ì—†ê±°ë‚˜ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ê´€ë ¨ë„ ë†’ì€ ë‚´ìš© ë°˜í™˜
            # ê¸´ ì¤„ì´ë‚˜ ì˜ë¯¸ìˆëŠ” ë‚´ìš© ìš°ì„ 
            meaningful_lines = []
            for line in answer_lines:
                # ë„ˆë¬´ ì§§ê±°ë‚˜ ì˜ë¯¸ì—†ëŠ” ì¤„ ì œì™¸
                if len(line.strip()) > 10 and not line.strip().startswith(('-', 'â€¢', '*')):
                    meaningful_lines.append(line)
            
            if meaningful_lines:
                return '\n'.join(meaningful_lines[:3])  # ìµœëŒ€ 3ì¤„
            else:
                return '\n'.join(answer_lines[:5])  # ìµœëŒ€ 5ì¤„
        else:
            return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•˜ì§€ë§Œ ì ì ˆí•œ ë‹µë³€ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    def _calculate_confidence(self, documents: List[Dict[str, Any]]) -> float:
        """ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        if not documents:
            return 0.0
        
        # í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ë°˜ ì‹ ë¢°ë„
        scores = [doc.get('score', 0) for doc in documents]
        avg_score = sum(scores) / len(scores)
        
        # ë¬¸ì„œ ìˆ˜ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
        doc_count_weight = min(len(documents) / self.config.max_retrieved_docs, 1.0)
        
        # ìµœì¢… ì‹ ë¢°ë„ (0~1 ë²”ìœ„)
        confidence = avg_score * doc_count_weight
        return round(confidence, 2)
    
    async def _evaluate_and_log_quality(self, user_prompt: str, context: str, answer: str):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ RAG í’ˆì§ˆ í‰ê°€ ë° MongoDB ë¡œê¹…"""
        try:
            logger.info("ğŸ” ë°±ê·¸ë¼ìš´ë“œ RAG í’ˆì§ˆ í‰ê°€ ì‹œì‘")
            
            # GPT-4.1ì„ ì´ìš©í•œ í’ˆì§ˆ í‰ê°€ ë° MongoDB ë¡œê¹…
            evaluation_result = await evaluate_and_log_rag(
                user_prompt=user_prompt,
                rag_context=context,
                rag_answer=answer
            )
            
            logger.info(
                f"âœ… RAG í’ˆì§ˆ í‰ê°€ ì™„ë£Œ - "
                f"ì „ì²´ì ìˆ˜: {evaluation_result.overall_score}/10, "
                f"ê´€ë ¨ì„±: {evaluation_result.relevance_score}/10, "
                f"ì •í™•ì„±: {evaluation_result.accuracy_score}/10, "
                f"ì™„ì„±ë„: {evaluation_result.completeness_score}/10"
            )
            
        except Exception as e:
            logger.error(f"âŒ ë°±ê·¸ë¼ìš´ë“œ RAG í’ˆì§ˆ í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
    
    async def get_system_status(self) -> Dict[str, Any]:
        """RAG ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        try:
            # ì¸ë±ì„œ ì •ë³´
            indexer = get_document_indexer()
            indexer_info = indexer.get_indexer_info()
            
            # ë²¡í„° ìŠ¤í† ì–´ ì •ë³´
            vector_info = indexer_info.get('vector_store_info', {})
            
            return {
                "rag_config": {
                    "embedding_model": self.config.embedding_model,
                    "max_retrieved_docs": self.config.max_retrieved_docs,
                    "similarity_threshold": self.config.similarity_threshold,
                    "max_context_length": self.config.max_context_length
                },
                "indexer_status": indexer_info,
                "total_indexed_documents": vector_info.get('total_entities', 0),
                "status": "active" if vector_info.get('total_entities', 0) > 0 else "no_documents"
            }
            
        except Exception as e:
            logger.error(f"ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"status": "error", "message": str(e)}

class SimpleRAGSystem:
    """ê°„ë‹¨í•œ RAG ì‹œìŠ¤í…œ (LLM ì—†ëŠ” ë²„ì „)"""
    
    def __init__(self):
        self.rag_system = RAGSystem()
    
    async def ask(self, question: str) -> str:
        """ê°„ë‹¨í•œ ì§ˆì˜ì‘ë‹µ"""
        response = await self.rag_system.query(question)
        return response.answer
    
    async def ask_with_details(self, question: str) -> Dict[str, Any]:
        """ìƒì„¸ ì •ë³´ì™€ í•¨ê»˜ ì§ˆì˜ì‘ë‹µ"""
        response = await self.rag_system.query(question)
        return {
            "answer": response.answer,
            "confidence": response.confidence_score,
            "sources": [doc.get('source_file') for doc in response.retrieved_documents],
            "retrieved_count": len(response.retrieved_documents)
        }

# ì§€ì—° ë¡œë”©ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
_rag_system = None
_simple_rag = None

def get_rag_system() -> RAGSystem:
    """RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì§€ì—° ë¡œë”©)"""
    global _rag_system
    
    if _rag_system is None:
        logger.info("ê¸°ë³¸ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        _rag_system = RAGSystem()
        logger.info("ê¸°ë³¸ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    return _rag_system

def get_simple_rag() -> SimpleRAGSystem:
    """Simple RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì§€ì—° ë¡œë”©)"""
    global _simple_rag
    
    if _simple_rag is None:
        logger.info("Simple RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        _simple_rag = SimpleRAGSystem()
        logger.info("Simple RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    return _simple_rag

# í¸ì˜ í•¨ìˆ˜ë“¤
async def rag_query(question: str, max_docs: int = None) -> RAGResponse:
    """RAG ì¿¼ë¦¬ í¸ì˜ í•¨ìˆ˜"""
    system = get_rag_system()
    return await system.query(question, max_docs)

async def simple_ask(question: str) -> str:
    """ê°„ë‹¨í•œ ì§ˆì˜ì‘ë‹µ í¸ì˜ í•¨ìˆ˜"""
    simple_rag = get_simple_rag()
    return await simple_rag.ask(question)

async def ask_with_context(question: str) -> Dict[str, Any]:
    """ì»¨í…ìŠ¤íŠ¸ í¬í•¨ ì§ˆì˜ì‘ë‹µ í¸ì˜ í•¨ìˆ˜"""
    simple_rag = get_simple_rag()
    return await simple_rag.ask_with_details(question)

async def get_rag_status() -> Dict[str, Any]:
    """RAG ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ í¸ì˜ í•¨ìˆ˜"""
    try:
        system = get_rag_system()
        return await system.get_system_status()
    except Exception as e:
        return {
            "status": "error", 
            "message": str(e),
            "rag_system": "ì´ˆê¸°í™” í•„ìš”"
        } 